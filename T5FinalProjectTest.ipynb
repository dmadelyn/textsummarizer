{"cells":[{"cell_type":"markdown","metadata":{"id":"NDfjE0ir7sSc"},"source":["# Text Summarization Project\n","\n","This notebook is dedicated to the task of text summarization using a fine-tuned T5 model. The goal is to effectively summarize large bodies of text into concise, meaningful summaries.\n","\n","## Description\n","\n","In this project, we are exploring different approaches to text summarization:\n","- Summarizing each paragraph individually and then stitching these summaries together.\n","- Summarizing the entire text in one go.\n","\n","We will compare these methods using ROUGE scores to evaluate their effectiveness.\n","\n","## Steps to Run\n","\n","1. **Add Data to the Runtime (IMPORTANT!)**: I'd say the first thing would be to add the data to the runtime on the side column. For us, we shoudl add the kindle_reviews.csv as well as the test.jsonl. Put both of those in the runtime, no need for folder nesting, etc. Should be sufficient as is.\n","\n","2. **Install Required Libraries**: First cell will install libraries. We are using PyTorch for this.\n","\n","3. **Model Fine-Tuning**: The model then creates a class that will prepare the summaries such that they are in a format to be fed in. In other words, we can't just input text, you have to show it that it's a text / summary pair so T5 knows.\n","\n","4. **Text Summarization**: In this section, we apply the fine-tuned model to summarize the test data. The two approaches (paragraph-by-paragraph and full-text summarization) are implemented and compared. Results are saved to an array. The last one is printed out for idk sanity I guess.\n","\n","5. **Evaluate Summaries**: The summaries generated by each method are evaluated using the ROUGE metric just imported easily. The results are displayed and compared to determine the more effective approach. Here is kinda a summary of what they can mean -\n","\n","Recall essentially answers the following question - \"Of all the relevent information present in the initial summary, how much did the generated summary manage to capture\"\n","\n","Precision answers the following question - \"Of all the information presented in the generated summary, how much of it is relevant or actually appears in the reference summary?\"\n","\n","## Notes\n","\n","One thing to be concerned about is the rapid amount of paragraphs... that's why I added the average paragraph to make sure it was spitting out something reasonable.\n","\n","Pretraining & actually predicting take a long time, so just be wary of that when running. I think that it takes around 10 seconds generally speaking to make a prediction and the training output it shown but it took me 4.5 minutes for say 1000 summaries."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11884,"status":"ok","timestamp":1703272259586,"user":{"displayName":"Tanay Chandak","userId":"17324861930604689779"},"user_tz":360},"id":"FFbkjg4Sybgx","outputId":"8b3a239c-e76e-4858-99d3-6b4e84e4a57b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.0)\n","Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install transformers datasets rouge-score torch sentencepiece accelerate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":627},"executionInfo":{"elapsed":7564,"status":"ok","timestamp":1703272267146,"user":{"displayName":"Tanay Chandak","userId":"17324861930604689779"},"user_tz":360},"id":"VYtvrL_nA8en","outputId":"199a16e9-bf6f-4ae0-bd7d-32ce9cc33bd0"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-2-c0e4de9f7a45>:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n","\n","\n","  df = pd.read_csv(\"kindle_reviews.csv\", error_bad_lines=False, nrows=100)\n"]},{"data":{"text/html":["\n","  <div id=\"df-688daae1-a451-4b3b-8df1-2934f2904f4d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>asin</th>\n","      <th>helpful</th>\n","      <th>overall</th>\n","      <th>reviewText</th>\n","      <th>reviewTime</th>\n","      <th>reviewerID</th>\n","      <th>reviewerName</th>\n","      <th>summary</th>\n","      <th>unixReviewTime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>B000F83SZQ</td>\n","      <td>[0, 0]</td>\n","      <td>5</td>\n","      <td>I enjoy vintage books and movies so I enjoyed ...</td>\n","      <td>05 5, 2014</td>\n","      <td>A1F6404F1VG29J</td>\n","      <td>Avidreader</td>\n","      <td>Nice vintage story</td>\n","      <td>1399248000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>B000F83SZQ</td>\n","      <td>[2, 2]</td>\n","      <td>4</td>\n","      <td>This book is a reissue of an old one; the auth...</td>\n","      <td>01 6, 2014</td>\n","      <td>AN0N05A9LIJEQ</td>\n","      <td>critters</td>\n","      <td>Different...</td>\n","      <td>1388966400</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>B000F83SZQ</td>\n","      <td>[2, 2]</td>\n","      <td>4</td>\n","      <td>This was a fairly interesting read.  It had ol...</td>\n","      <td>04 4, 2014</td>\n","      <td>A795DMNCJILA6</td>\n","      <td>dot</td>\n","      <td>Oldie</td>\n","      <td>1396569600</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>B000F83SZQ</td>\n","      <td>[1, 1]</td>\n","      <td>5</td>\n","      <td>I'd never read any of the Amy Brewster mysteri...</td>\n","      <td>02 19, 2014</td>\n","      <td>A1FV0SX13TWVXQ</td>\n","      <td>Elaine H. Turley \"Montana Songbird\"</td>\n","      <td>I really liked it.</td>\n","      <td>1392768000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>B000F83SZQ</td>\n","      <td>[0, 1]</td>\n","      <td>4</td>\n","      <td>If you like period pieces - clothing, lingo, y...</td>\n","      <td>03 19, 2014</td>\n","      <td>A3SPTOKDG7WBLN</td>\n","      <td>Father Dowling Fan</td>\n","      <td>Period Mystery</td>\n","      <td>1395187200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-688daae1-a451-4b3b-8df1-2934f2904f4d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-688daae1-a451-4b3b-8df1-2934f2904f4d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-688daae1-a451-4b3b-8df1-2934f2904f4d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-63cce845-9329-4d0e-b201-9cc15b43b480\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-63cce845-9329-4d0e-b201-9cc15b43b480')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-63cce845-9329-4d0e-b201-9cc15b43b480 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["   Unnamed: 0        asin helpful  overall  \\\n","0           0  B000F83SZQ  [0, 0]        5   \n","1           1  B000F83SZQ  [2, 2]        4   \n","2           2  B000F83SZQ  [2, 2]        4   \n","3           3  B000F83SZQ  [1, 1]        5   \n","4           4  B000F83SZQ  [0, 1]        4   \n","\n","                                          reviewText   reviewTime  \\\n","0  I enjoy vintage books and movies so I enjoyed ...   05 5, 2014   \n","1  This book is a reissue of an old one; the auth...   01 6, 2014   \n","2  This was a fairly interesting read.  It had ol...   04 4, 2014   \n","3  I'd never read any of the Amy Brewster mysteri...  02 19, 2014   \n","4  If you like period pieces - clothing, lingo, y...  03 19, 2014   \n","\n","       reviewerID                         reviewerName             summary  \\\n","0  A1F6404F1VG29J                           Avidreader  Nice vintage story   \n","1   AN0N05A9LIJEQ                             critters        Different...   \n","2   A795DMNCJILA6                                  dot               Oldie   \n","3  A1FV0SX13TWVXQ  Elaine H. Turley \"Montana Songbird\"  I really liked it.   \n","4  A3SPTOKDG7WBLN                   Father Dowling Fan      Period Mystery   \n","\n","   unixReviewTime  \n","0      1399248000  \n","1      1388966400  \n","2      1396569600  \n","3      1392768000  \n","4      1395187200  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import csv\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","from datasets import load_dataset, load_metric\n","from torch.utils.data import Dataset, DataLoader\n","\n","df = pd.read_csv(\"kindle_reviews.csv\", error_bad_lines=False, nrows=100)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":711,"status":"ok","timestamp":1703272267851,"user":{"displayName":"Tanay Chandak","userId":"17324861930604689779"},"user_tz":360},"id":"3u0s-nldA_dL","outputId":"3ea6e322-064a-485e-81ec-a0b6d3c67939"},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["class KindleReviewDataset(Dataset):\n","    def __init__(self, tokenizer, data, max_length=512):\n","        self.tokenizer = tokenizer\n","        self.data = data\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        item = self.data.iloc[idx]\n","        text = item['reviewText']\n","        summary = item['summary']\n","        inputs = self.tokenizer.encode_plus(\n","            text, max_length=self.max_length, truncation=True, padding='max_length', return_tensors='pt')\n","        targets = self.tokenizer.encode_plus(\n","            summary, max_length=self.max_length, truncation=True, padding='max_length', return_tensors='pt')\n","        return {\n","            'input_ids': inputs['input_ids'].flatten(),\n","            'attention_mask': inputs['attention_mask'].flatten(),\n","            'labels': targets['input_ids'].flatten()\n","        }\n","\n","tokenizer = T5Tokenizer.from_pretrained('t5-small')\n","dataset = KindleReviewDataset(tokenizer, df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":438},"executionInfo":{"elapsed":37608,"status":"ok","timestamp":1703272305457,"user":{"displayName":"Tanay Chandak","userId":"17324861930604689779"},"user_tz":360},"id":"3wAod4w4E1mx","outputId":"a7eed33c-a339-4b84-adc8-6a18ac28a864"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['Unnamed: 0', 'asin', 'helpful', 'overall', 'reviewText', 'reviewTime',\n","       'reviewerID', 'reviewerName', 'summary', 'unixReviewTime'],\n","      dtype='object')\n","100\n","Using device: cuda\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [75/75 00:26, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>24.449000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>24.169500</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>24.284500</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>22.178500</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>22.956500</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>21.009300</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>20.622200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=75, training_loss=22.60388264973958, metrics={'train_runtime': 30.2981, 'train_samples_per_second': 9.902, 'train_steps_per_second': 2.475, 'total_flos': 40602540441600.0, 'train_loss': 22.60388264973958, 'epoch': 3.0})"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import Trainer, TrainingArguments\n","import torch\n","\n","print(df.columns)\n","print(len(df))\n","\n","# important to use google collab torch instead (if we want to pay, >>)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)\n","\n","# fine tunes & trains... not sure if we want to mess with this stuff\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=4,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=10,\n",")\n","\n","# trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset,\n",")\n","\n","trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jB3RjG-4zXS9","outputId":"1e659587-1347-4a87-f793-e6665491c1aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["is living the PRISON HIGH LIFE... at least compared to the... at least compared to the... at least compared to the PRISON HIGH LIFE. -- and TMZ has the menu to prove it. TMZ has the menu to prove it. click here for a complete list of TMZ products. the TMZ. first meal............................................................ Lauryn was serving 3-month sentence for tax evasion. she was served some pulled pork with a side of carrots, peas and sweet potatoes. she was able to choose from an array of juices or milk. the first meal included scrambled eggs and grits, chop suey with green beans and bread. the first meal at Bristol County Jail included scrambled eggs and grits. hill is housed in barracks so she can have fun with other inmates. at night, she's housed in barracks so she can laugh and talk. Hernandez is being kept in a 3x5 cell for 21 hours a day, only allowed out for three hours a day. he's all alone in solitary confinement. if you're gonna break the law... try not to murder a guy (or three). it's better that way than killing a guy (or three).\n","TMZ has the menu to prove it. if you're gonna murder a guy, try not to murder a guy (or three)... try not to murder a guy (or three)... it's better that way.\n","{'url': 'http://www.tmz.com/2013/07/08/lauryn-hill-prison-sentence-food', 'archive': 'http://web.archive.org/web/20160808141848id_/http://www.tmz.com:80/2013/07/08/lauryn-hill-prison-sentence-food', 'title': 'Lauryn Hill to Aaron Hernandez -- My Prison Food Is WAYYY Better Than Yours!', 'date': '20160808141848', 'text': \"is living the PRISON HIGH LIFE ... at least compared to\\n\\n-- and TMZ has the menu to prove it.\\n\\nLet's start with their first meals ...\\n\\nWhen Lauryn checked into Federal Correctional Institute in Connecticut on Monday to serve her 3-month sentence for tax evasion, she was served up with some tasty BBQ pulled pork with a side of carrots, peas and sweet potatoes. To wash it down: she was able to choose from an array of juices or milk. WHO'S HUNGRY?\\n\\nCompare that to Hernandez ... whose first meal at Bristol County Jail included scrambled eggs and grits, and chop suey with green beans and bread. Prison chop suey? No thanks.\\n\\nAs for day-to-day life, Hill will do menial work like cleaning the grounds, educational department help, yard work, or working in the religious services department. At night, she's housed in barracks with other inmates so she can laugh and talk and have fun!\\n\\nHernandez is being kept in a 3x5 cell for 21 hours a day, only allowed out for three hours a day, allegedly for his own safety. Oh ... and he's all alone in solitary confinement. Boooooring!\\n\\nSo, what's the lesson here? If you're gonna break the law ... try not to (allegedly) murder a guy (or three) ... it's better that way.\", 'summary': \"Lauryn Hill is living the PRISON HIGH LIFE ... at least compared to Aaron Hernandez -- and TMZ has the menu to prove it. Let's start with their firstâ€¦\", 'compression': 8.34375, 'coverage': 0.9375, 'density': 8.125, 'compression_bin': 'low', 'coverage_bin': 'medium', 'density_bin': 'mixed'}\n"]}],"source":["import json\n","\n","# summarizing text function\n","def summarize_text(text, tokenizer, model):\n","    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n","    inputs = inputs.to(model.device)\n","    outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# laod first x from dataset (im gonna use 100 for now, we can change it later so it doesn't blow up)\n","test_data = []\n","with open('test.jsonl', 'r') as file:\n","    for i, line in enumerate(file):\n","        if i < 300:\n","            test_data.append(json.loads(line))\n","        else:\n","            break\n","\n","# summarize each paragraph vs entire text\n","paragraph_summaries = []\n","full_text_summaries = []\n","for article in test_data:\n","    # kinda does a lot of paragraph breaks just by nature of the way articles are written\n","    paragraphs = article['text'].split('\\n\\n')\n","    stitched_summary = ' '.join([summarize_text(para, tokenizer, model) for para in paragraphs if para.strip()])\n","    full_summary = summarize_text(article['text'], tokenizer, model)\n","    paragraph_summaries.append(stitched_summary)\n","    full_text_summaries.append(full_summary)\n","\n","# just printing an example summary here\n","print(paragraph_summaries[-1])\n","print(full_text_summaries[-1])\n","print(test_data[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wWYkMO5c0hC-","outputId":"7a06b833-4c74-46f2-ee6b-d80bd7528b12"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average paragraphs per article: 13.72\n"]}],"source":["# small code block I wrote to calculate the average number of sentances in the text...\n","\n","total_paragraphs = 0\n","\n","for article in test_data:\n","    paragraphs = article['text'].split('\\n\\n')\n","    non_empty_paragraphs = sum(1 for para in paragraphs if para.strip())\n","    total_paragraphs += non_empty_paragraphs\n","\n","average_paragraphs_per_article = total_paragraphs / len(test_data)\n","print(\"Average paragraphs per article:\", average_paragraphs_per_article)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"referenced_widgets":["3b6563d1f60245d1afa6ba76461fd055"]},"id":"I4zOitP5zwQ1","outputId":"d4da40c7-ea0e-44c5-ff87-77902d755575"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-8-bea26787d523>:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n","  rouge = load_metric(\"rouge\")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.0/metrics/rouge/rouge.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b6563d1f60245d1afa6ba76461fd055","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["ROUGE Scores for Paragraph Summaries: {'rouge1': AggregateScore(low=Score(precision=0.05573424229844668, recall=0.6605562492825988, fmeasure=0.09699070931016533), mid=Score(precision=0.06294917928635888, recall=0.6851262994184149, fmeasure=0.10734230453600091), high=Score(precision=0.07085429815911162, recall=0.7072498522176931, fmeasure=0.11832494519705482)), 'rouge2': AggregateScore(low=Score(precision=0.030229113788854903, recall=0.33440294443037705, fmeasure=0.052103955842789124), mid=Score(precision=0.035526304147783024, recall=0.364822343932637, fmeasure=0.05990535850025359), high=Score(precision=0.041008066921472866, recall=0.39540302075230044, fmeasure=0.06834468016580406)), 'rougeL': AggregateScore(low=Score(precision=0.04316881976893632, recall=0.5206239387348603, fmeasure=0.07528822303972534), mid=Score(precision=0.04911473744331071, recall=0.5416808568480087, fmeasure=0.08375355275423835), high=Score(precision=0.05514836779080362, recall=0.5640639819497478, fmeasure=0.09215972366294692)), 'rougeLsum': AggregateScore(low=Score(precision=0.04378046303287278, recall=0.519450544128103, fmeasure=0.07554587162587582), mid=Score(precision=0.04929668415837826, recall=0.5438066085407742, fmeasure=0.08401772360668115), high=Score(precision=0.05584863115885776, recall=0.5664669732318584, fmeasure=0.0931650625700932))}\n","AggregateScore(low=Score(precision=0.05573424229844668, recall=0.6605562492825988, fmeasure=0.09699070931016533), mid=Score(precision=0.06294917928635888, recall=0.6851262994184149, fmeasure=0.10734230453600091), high=Score(precision=0.07085429815911162, recall=0.7072498522176931, fmeasure=0.11832494519705482))\n","ROUGE Scores for Full Text Summaries: {'rouge1': AggregateScore(low=Score(precision=0.19420510620561562, recall=0.3003074836015274, fmeasure=0.21545182926520848), mid=Score(precision=0.2131313182999441, recall=0.3204709359281317, fmeasure=0.2308371989102988), high=Score(precision=0.23382634353678927, recall=0.34211858333734496, fmeasure=0.24669876904911206)), 'rouge2': AggregateScore(low=Score(precision=0.07692417649605875, recall=0.10625503146241076, fmeasure=0.08065930146453693), mid=Score(precision=0.09331360325753757, recall=0.1253176211468338, fmeasure=0.09461583998673209), high=Score(precision=0.11032770500037593, recall=0.14491467654003498, fmeasure=0.11075007459946723)), 'rougeL': AggregateScore(low=Score(precision=0.15303712278230072, recall=0.23848188225097655, fmeasure=0.1695587778481928), mid=Score(precision=0.16898292624494626, recall=0.2575958238459616, fmeasure=0.18394697746558078), high=Score(precision=0.1856484041379005, recall=0.27731270774682354, fmeasure=0.19841007850415798)), 'rougeLsum': AggregateScore(low=Score(precision=0.15218136804687726, recall=0.23900961695951994, fmeasure=0.1695713150553557), mid=Score(precision=0.16930255465560676, recall=0.2587635370621354, fmeasure=0.18482670368883825), high=Score(precision=0.1872382666802757, recall=0.2781922058605083, fmeasure=0.19869624555764245))}\n","AggregateScore(low=Score(precision=0.19420510620561562, recall=0.3003074836015274, fmeasure=0.21545182926520848), mid=Score(precision=0.2131313182999441, recall=0.3204709359281317, fmeasure=0.2308371989102988), high=Score(precision=0.23382634353678927, recall=0.34211858333734496, fmeasure=0.24669876904911206))\n"]}],"source":["# just using library\n","from datasets import load_metric\n","\n","rouge = load_metric(\"rouge\")\n","\n","def calculate_rouge(predictions, references):\n","    return rouge.compute(predictions=predictions, references=references)\n","\n","rouge_scores_paragraph = calculate_rouge(paragraph_summaries, [article['summary'] for article in test_data])\n","rouge_scores_full = calculate_rouge(full_text_summaries, [article['summary'] for article in test_data])\n","\n","print(\"ROUGE Scores for Paragraph Summaries:\", rouge_scores_paragraph)\n","print(rouge_scores_paragraph['rouge1'])\n","print(\"ROUGE Scores for Full Text Summaries:\", rouge_scores_full)\n","print(rouge_scores_full['rouge1'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MeNBT20nYMeh"},"outputs":[],"source":["# determining which articles have the highest precision on a paragraph / full text level\n","\n","best_paragraph, para_precision, para_index = '', -float('inf'), -1\n","best_full, full_precision, full_index = '', -float('inf'), -1\n","\n","for i, article in enumerate(test_data):\n","  rouge_scores_paragraph = calculate_rouge([paragraph_summaries[i]], [article['summary']])\n","  rouge_scores_full = calculate_rouge([full_text_summaries[i]], [article['summary']])\n","  if rouge_scores_paragraph['rouge1'][1][0] > para_precision:\n","    best_paragraph, para_precision, para_index = article['summary'], rouge_scores_paragraph['rouge1'][1][0], i\n","  if rouge_scores_full['rouge1'][1][0] > full_precision:\n","    best_full, full_precision, full_index = article['summary'], rouge_scores_full['rouge1'][1][0], i\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UEFel0JtlOWF"},"outputs":[],"source":["# determining which articles have the highest recall on a paragraph / full text level\n","\n","best_paragraph, para_recall, para_index = '', -float('inf'), -1\n","best_full, full_recall, full_index = '', -float('inf'), -1\n","perfect_recall = 0 # counting how many articles have a recall of 1.0\n","\n","for i, article in enumerate(test_data):\n","  rouge_scores_paragraph = calculate_rouge([paragraph_summaries[i]], [article['summary']])\n","  rouge_scores_full = calculate_rouge([full_text_summaries[i]], [article['summary']])\n","  if rouge_scores_paragraph['rouge1'][1][1] > para_recall:\n","    best_paragraph, para_recall, para_index = article['summary'], rouge_scores_paragraph['rouge1'][1][1], i\n","  if rouge_scores_full['rouge1'][1][1] > full_recall:\n","    best_full, full_recall, full_index = article['summary'], rouge_scores_full['rouge1'][1][1], i\n","\n","\n","  if rouge_scores_paragraph['rouge1'][1][1] == 1.0 or rouge_scores_full['rouge1'][1][1] == 1.0:\n","    perfect_recall += 1\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}